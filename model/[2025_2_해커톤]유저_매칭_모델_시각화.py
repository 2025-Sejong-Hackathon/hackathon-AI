# -*- coding: utf-8 -*-
"""[2025-2 í•´ì»¤í†¤]ìœ ì € ë§¤ì¹­ ëª¨ë¸_ì‹œê°í™”.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mTKEqnL9Fd1M6arSm0uEEDRu3Ub3zL31
"""

# 1. ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜
!sudo apt-get update -y
!sudo apt-get install -y fonts-nanum

# 2. í°íŠ¸ ìºì‹œ ê°±ì‹ 
!sudo fc-cache -fv

# 3. matplotlib ìºì‹œ ì‚­ì œ (ì¤‘ìš”)
!rm ~/.cache/matplotlib -rf

print("í°íŠ¸ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒë‹¨ ë©”ë‰´ì˜ [ëŸ°íƒ€ì„] -> [ì„¸ì…˜ ë‹¤ì‹œ ì‹œì‘]ì„ í´ë¦­í•˜ì„¸ìš”!")

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import pandas as pd
import numpy as np

# 1. í°íŠ¸ ê²½ë¡œ ì„¤ì • (ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•)
plt.rc('font', family='NanumBarunGothic')

# 2. ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
plt.rc('axes', unicode_minus=False)

# 3. í°íŠ¸ê°€ ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ í…ŒìŠ¤íŠ¸ ê·¸ë˜í”„ ê·¸ë ¤ë³´ê¸°
plt.figure(figsize=(5, 5))
plt.title("í•œê¸€ í°íŠ¸ í…ŒìŠ¤íŠ¸")
plt.plot([1, 2, 3], [1, 4, 9])
plt.text(2, 4, "í•œê¸€ ì˜ ë‚˜ì˜µë‹ˆë‹¤!", ha='center')
plt.show()

# --- í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´ ì•„ê¹Œ ê·¸ ì „ì²´ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš” ---

W_P = 4  # Personality (ì„±ê²©/ì˜ˆë¯¼)
W_S = 3  # Sleep (ìˆ˜ë©´)
W_C = 2  # Cleanliness (ì²­ê²°)

# ê° í•­ëª©ë³„ ê°€ì¤‘ì¹˜ ë§¤í•‘
weight_A = {
    # [ìˆ˜ë©´ íŒ¨í„´]
    "sleep_habit": W_S,       # ì·¨ì¹¨ ì‹œê°„
    "wake_up": W_S,           # ê¸°ìƒ ì‹œê°„
    "activity_time": W_S,     # ì£¼ í™œë™ ì‹œê°„
    "out_return": W_S,        # ì™¸ì¶œ/ë³µê·€ ì˜ˆë¯¼ë„

    # [ì²­ê²°ë„]
    "clean_immediate": W_C,   # ë¨¸ë¦¬ì¹´ë½ ì¹˜ìš°ê¸°
    "desk_status": W_C,       # ì±…ìƒ ì •ë¦¬
    "clean_cycle": W_C,       # ì²­ì†Œ ì£¼ê¸° (0~3)
    "other_seat_tol": W_C,    # íƒ€ì¸ ìë¦¬ ë”ëŸ¬ì›€ í—ˆìš©ë„

    # [ì„±ê²©/ì˜ˆë¯¼í•¨/ìƒí™œì–‘ì‹]
    "phone_noise": W_P,       # í†µí™” ì†ŒìŒ
    "light_sensitivity": W_P, # ë¶ˆ ì¼œê³  ì 
    "key_mouse_noise": W_P,   # íƒ€ê±´ ì†ŒìŒ
    "alarm_habit": W_P,       # ì•ŒëŒ ìŠµê´€
    "social_willingness": W_P,# ì¹œëª© ë„ëª¨
    "friend_invite": W_P,     # ì¹œêµ¬ ì´ˆëŒ€
    "dorm_stay": W_P,         # ê¸°ìˆ™ì‚¬ ì²´ë¥˜ ì‹œê°„
    "space_privacy": W_P      # ì˜ì—­ ì¹¨ë²”
}

import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
import platform
from sklearn.manifold import TSNE # ìƒë‹¨ì— ì¶”ê°€
from mpl_toolkits.mplot3d import Axes3D

# ---------------------------------------------------------
# 0. ì‹œê°í™” í°íŠ¸ ì„¤ì • (OSë³„ ìë™í™”)
# ---------------------------------------------------------
system_name = platform.system()
if system_name == 'Darwin': # Mac
    plt.rc('font', family='AppleGothic')
elif system_name == 'Windows': # Windows
    plt.rc('font', family='Malgun Gothic')
else: # Linux (Colab ë“±)
    # Colabì—ì„œëŠ” ë‚˜ëˆ”ê¸€ê¼´ ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
    plt.rc('font', family='NanumBarunGothic')
plt.rcParams['axes.unicode_minus'] = False

# ---------------------------------------------------------
# 1. ë§¤ì¹­ ì—”ì§„ í´ë˜ìŠ¤ (ìˆ˜ì •ë¨)
# ---------------------------------------------------------
class DormMatchAI_Advanced:
    def __init__(self, data_path):
        self.data_path = data_path
        self.users_df = None
        self.weighted_features = None

        # [ìˆ˜ì • 1] ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬ ì§ì ‘ ì •ì˜ (ì„±ê²©4 : ìˆ˜ë©´3 : ì²­ê²°1)
        self.weights = weight_A

        # [ìˆ˜ì • 2] ê²°ê³¼ í•´ì„ìš© í…ìŠ¤íŠ¸ ë§¤í•‘ ë³´ì™„
        self.text_map = {
            "sleep_habit": {0: "12ì‹œì „ ì·¨ì¹¨", 1: "ìƒˆë²½ ì·¨ì¹¨"},
            "wake_up": {0: "ëŠ¦ì /ì˜¤í›„", 1: "ì•„ì¹¨ ê¸°ìƒ"},
            "activity_time": {0: "ë‚® í™œë™", 1: "ë°¤ í™œë™"},
            "clean_cycle": {0: "ë§¤ì¼", 1: "3ì¼ë§ˆë‹¤", 2: "1ì£¼ë§ˆë‹¤", 3: "1ë‹¬ë§ˆë‹¤"},
            "phone_noise": {0: "ìƒê´€ì—†ìŒ", 1: "ë‚˜ê°€ì„œ í†µí™”"},
            "clean_immediate": {0: "ë‚˜ì¤‘ì—", 1: "ë°”ë¡œë°”ë¡œ"},
            "social_willingness": {0: "ê°œì¸ì£¼ì˜", 1: "ì¹œëª©ì„ í˜¸"},
            "is_smoker": {True: "í¡ì—°", False: "ë¹„í¡ì—°"}
        }

        # í•œê¸€ í•­ëª©ëª… ë§¤í•‘
        self.col_name_map = {
            "sleep_habit": "ìˆ˜ë©´ì‹œê°„", "wake_up": "ê¸°ìƒì‹œê°„", "activity_time": "í™œë™ì‹œê°„",
            "clean_cycle": "ì²­ì†Œì£¼ê¸°", "phone_noise": "í†µí™”ì†ŒìŒ", "space_privacy": "ê³µê°„ì¡´ì¤‘",
            "clean_immediate": "ì •ë¦¬ìŠµê´€", "social_willingness": "ì‚¬íšŒì„±"
        }

    def load_and_preprocess(self):
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # [ìˆ˜ì • 3] ë°ì´í„° ë¡œë”© ë¡œì§ ê°„ì†Œí™” (ì´ë¯¸ Flatí•œ êµ¬ì¡°ì„)
        # ìƒì„±ëœ JSONì€ ì¤‘ì²©ì´ ì—†ìœ¼ë¯€ë¡œ ë°”ë¡œ DataFrameìœ¼ë¡œ ë³€í™˜
        self.users_df = pd.DataFrame(data)

        # ê°€ì¤‘ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
        self.feature_cols = list(self.weights.keys())

        # ì •ê·œí™” ë° ê°€ì¤‘ì¹˜ ì ìš©
        scaler = MinMaxScaler()
        # ë°ì´í„°í”„ë ˆì„ì—ì„œ feature_colsë§Œ ë½‘ì•„ì„œ ì •ê·œí™”
        features_norm = scaler.fit_transform(self.users_df[self.feature_cols])
        self.weighted_features = pd.DataFrame(features_norm, columns=self.feature_cols)

        # ê°€ì¤‘ì¹˜ ê³±í•˜ê¸°
        for col, weight in self.weights.items():
            self.weighted_features[col] *= weight

    def train_clustering(self, n_clusters=12):
        # K-Means ìˆ˜í–‰
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        self.users_df['cluster_id'] = kmeans.fit_predict(self.weighted_features)
        print(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: ì „ì²´ ìœ ì €ë¥¼ {n_clusters}ê°œì˜ ì„±í–¥ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.")

    def explain_match_detail(self, me_row, partner_row):
        """ë§¤ì¹­ëœ ì´ìœ  ë¶„ì„"""
        reasons = {"match": [], "conflict": []}

        for col in self.feature_cols:
            val_me = me_row[col]
            val_partner = partner_row[col]

            col_name_kr = self.col_name_map.get(col, col)

            # ê°’ì´ ë¹„ìŠ·í•˜ë©´ ë§¤ì¹­ ì„±ê³µ (ì™„ì „ ì¼ì¹˜ê°€ ì•„ë‹ˆë”ë¼ë„ ì°¨ì´ê°€ ì ìœ¼ë©´)
            if val_me == val_partner:
                  reasons["match"].append(col_name_kr)
            else:
                # ê°’ì´ ë‹¤ë¥´ë©´ ê°ˆë“± ìš”ì†Œ
                my_val_txt = self.text_map.get(col, {}).get(val_me, str(val_me))
                pt_val_txt = self.text_map.get(col, {}).get(val_partner, str(val_partner))
                reasons["conflict"].append(f"{col_name_kr}(ë‚˜:{my_val_txt} vs ìŸ¤:{pt_val_txt})")

        return reasons

    def find_best_match(self, target_student_id, top_n=3):
        # [ìˆ˜ì • 4] user_id ëŒ€ì‹  student_id ì‚¬ìš©
        try:
            target_idx = self.users_df[self.users_df['student_id'] == target_student_id].index[0]
        except IndexError:
            print(f"âŒ ì—ëŸ¬: í•™ë²ˆ {target_student_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], -1

        target_vec = self.weighted_features.iloc[target_idx].values.reshape(1, -1)
        target_gender = self.users_df.iloc[target_idx]['gender']
        target_cluster = self.users_df.iloc[target_idx]['cluster_id']

        # í›„ë³´êµ° í•„í„°ë§: ì„±ë³„ ì¼ì¹˜ AND ê°™ì€ í´ëŸ¬ìŠ¤í„°
        candidates = self.users_df[
            (self.users_df['student_id'] != target_student_id) &
            (self.users_df['gender'] == target_gender) &
            (self.users_df['cluster_id'] == target_cluster)
        ].copy()

        # ì˜ˆì™¸ ì²˜ë¦¬: ê°™ì€ í´ëŸ¬ìŠ¤í„°ì— ì‚¬ëŒì´ ì—†ìœ¼ë©´ ì „ì²´ í™•ì¥
        if len(candidates) < top_n:
             print("âš ï¸ ê°™ì€ ì„±í–¥ ê·¸ë£¹ ë‚´ í›„ë³´ ë¶€ì¡± -> ì „ì²´ ê·¸ë£¹ìœ¼ë¡œ í™•ì¥ ê²€ìƒ‰")
             candidates = self.users_df[
                (self.users_df['student_id'] != target_student_id) &
                (self.users_df['gender'] == target_gender)
            ].copy()

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        candidate_vecs = self.weighted_features.loc[candidates.index]
        sims = cosine_similarity(target_vec, candidate_vecs)[0]
        candidates['match_score'] = sims * 100

        # Top N ì„ ì •
        top_matches = candidates.sort_values(by='match_score', ascending=False).head(top_n)

        results = []
        me_row = self.users_df.iloc[target_idx]

        for _, partner_row in top_matches.iterrows():
            explanation = self.explain_match_detail(me_row, partner_row)
            match_info = partner_row.to_dict()
            match_info['explanation'] = explanation
            results.append(match_info)

        return results, target_student_id

    def visualize1(self, target_student_id, top_matches):
        # 1. PCA ì°¨ì› ì¶•ì†Œ ë° ë°ì´í„°í”„ë ˆì„ ìƒì„±
# [ìˆ˜ì •ë¨] 1. PCA ëŒ€ì‹  t-SNE ì‚¬ìš©
        # n_components=2: 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
        # perplexity: ë³´í†µ 30~50 ì‚¬ì´ë¥¼ ì”ë‹ˆë‹¤. ë°ì´í„°ê°€ ì ë‹¤ë©´(ìˆ˜ë°± ê°œ ì´í•˜) 5~10 ì •ë„ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.
        # random_state: ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ëª¨ì–‘ì´ ë°”ë€Œì§€ ì•Šë„ë¡ ê³ ì •
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        tsne_points = tsne.fit_transform(self.weighted_features)

        viz_df = pd.DataFrame(tsne_points, columns=['x', 'y'])
        viz_df['cluster'] = self.users_df['cluster_id']

        # 2. Jittering (t-SNEëŠ” ê·¸ë£¹ ê°„ ê±°ë¦¬ê°€ ë©€ì–´ì§€ë¯€ë¡œ noise_levelì„ ì¡°ê¸ˆ ì¤„ì—¬ë„ ë©ë‹ˆë‹¤)
        noise_level = 0.5 # t-SNE ì¢Œí‘œê°’ì€ PCAë³´ë‹¤ í´ ìˆ˜ ìˆì–´ì„œ ìƒí™© ë´ì„œ ì¡°ì • (ë³´í†µ 0.5~1.0 ì¶”ì²œ)
        viz_df['x'] = viz_df['x'] + np.random.normal(0, noise_level, size=len(viz_df))
        viz_df['y'] = viz_df['y'] + np.random.normal(0, noise_level, size=len(viz_df))

        # 3. [í•µì‹¬ ë³€ê²½] ìƒ‰ìƒ êµ¬ë¶„ ë¡œì§
        # íƒ€ê²Ÿ ìœ ì €ì˜ ì¸ë±ìŠ¤ ë° í´ëŸ¬ìŠ¤í„° ID ì°¾ê¸°
        target_idx = self.users_df[self.users_df['student_id'] == target_student_id].index[0]
        target_cluster = self.users_df.iloc[target_idx]['cluster_id']

        # 'color_group' ì»¬ëŸ¼ ìƒì„±: ë‚´ í´ëŸ¬ìŠ¤í„°='Same Group', ë‚˜ë¨¸ì§€='Others'
        viz_df['color_group'] = viz_df['cluster'].apply(
            lambda x: 'ë‚˜ì™€ ê°™ì€ ì„±í–¥ ê·¸ë£¹' if x == target_cluster else 'ë‹¤ë¥¸ ì„±í–¥ ê·¸ë£¹ë“¤'
        )

        # ì‹œê°í™” ì‹œì‘
        plt.figure(figsize=(12, 8))

        # 4. ë°°ê²½ ì‚°ì ë„ ê·¸ë¦¬ê¸° (ì»¤ìŠ¤í…€ íŒ”ë ˆíŠ¸ ì‚¬ìš©)
        sns.scatterplot(
            x='x', y='y',
            hue='color_group', # í´ëŸ¬ìŠ¤í„° ID ëŒ€ì‹  ìƒˆë¡œ ë§Œë“  ê·¸ë£¹ìœ¼ë¡œ ìƒ‰ìƒ êµ¬ë¶„
            data=viz_df,
            palette={'ë‚˜ì™€ ê°™ì€ ì„±í–¥ ê·¸ë£¹': '#2ca02c', 'ë‹¤ë¥¸ ì„±í–¥ ê·¸ë£¹ë“¤': '#d3d3d3'}, # ì´ˆë¡ìƒ‰ vs íšŒìƒ‰
            alpha=0.7, s=80, legend='full'
        )

        # 5. ë‚˜(Me)ì™€ ì¶”ì²œ ë£¸ë©”ì´íŠ¸ í•˜ì´ë¼ì´íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼, ì¢Œí‘œëŠ” Jitter ì ìš©ëœ ê°’ ì‚¬ìš©)
        plt.scatter(viz_df.iloc[target_idx]['x'], viz_df.iloc[target_idx]['y'],
                    c='red', s=400, marker='*', label='ë‚˜ (Me)', edgecolors='white', linewidth=2, zorder=10)

        for i, match in enumerate(top_matches):
            p_idx = self.users_df[self.users_df['student_id'] == match['student_id']].index[0]
            plt.scatter(viz_df.iloc[p_idx]['x'], viz_df.iloc[p_idx]['y'],
                        c='blue', s=200, marker='X', label=f'ì¶”ì²œ {i+1}ìœ„', edgecolors='white', linewidth=1, zorder=10)

            # í™”ì‚´í‘œ ê·¸ë¦¬ê¸°
            plt.arrow(viz_df.iloc[target_idx]['x'], viz_df.iloc[target_idx]['y'],
                      viz_df.iloc[p_idx]['x'] - viz_df.iloc[target_idx]['x'],
                      viz_df.iloc[p_idx]['y'] - viz_df.iloc[target_idx]['y'],
                      color='gray', alpha=0.5, linestyle='--', width=0.002, zorder=9)

        # 6. ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        plt.title(f'AI ê¸°ìˆ™ì‚¬ ë§¤ì¹­ ì‹œê°í™” (í•™ë²ˆ: {target_student_id})', fontsize=16)
        plt.xlabel('ì„±í–¥ PC1')
        plt.ylabel('ì„±í–¥ PC2')
        # ë²”ë¡€ ìˆœì„œ ë° ìœ„ì¹˜ ì¡°ì •
        handles, labels = plt.gca().get_legend_handles_labels()
        order = [0, 1, 2, 3, 4] # ë²”ë¡€ í‘œì‹œ ìˆœì„œ (ê·¸ë£¹2ê°œ + ë‚˜ + ì¶”ì²œ3ëª…)
        plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper right')

        plt.grid(True, alpha=0.2)
        plt.show()

    def visualize2(self, target_student_id, top_matches):
              # 1. PCA ì°¨ì› ì¶•ì†Œ ë° ë°ì´í„°í”„ë ˆì„ ìƒì„±
# [ìˆ˜ì •ë¨] 1. PCA ëŒ€ì‹  t-SNE ì‚¬ìš©
        # n_components=2: 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
        # perplexity: ë³´í†µ 30~50 ì‚¬ì´ë¥¼ ì”ë‹ˆë‹¤. ë°ì´í„°ê°€ ì ë‹¤ë©´(ìˆ˜ë°± ê°œ ì´í•˜) 5~10 ì •ë„ë¡œ ë‚®ì¶°ë³´ì„¸ìš”.
        # random_state: ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ëª¨ì–‘ì´ ë°”ë€Œì§€ ì•Šë„ë¡ ê³ ì •
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        tsne_points = tsne.fit_transform(self.weighted_features)

        viz_df = pd.DataFrame(tsne_points, columns=['x', 'y'])
        viz_df['cluster'] = self.users_df['cluster_id']

        # 2. Jittering (t-SNEëŠ” ê·¸ë£¹ ê°„ ê±°ë¦¬ê°€ ë©€ì–´ì§€ë¯€ë¡œ noise_levelì„ ì¡°ê¸ˆ ì¤„ì—¬ë„ ë©ë‹ˆë‹¤)
        noise_level = 0.5 # t-SNE ì¢Œí‘œê°’ì€ PCAë³´ë‹¤ í´ ìˆ˜ ìˆì–´ì„œ ìƒí™© ë´ì„œ ì¡°ì • (ë³´í†µ 0.5~1.0 ì¶”ì²œ)
        viz_df['x'] = viz_df['x'] + np.random.normal(0, noise_level, size=len(viz_df))
        viz_df['y'] = viz_df['y'] + np.random.normal(0, noise_level, size=len(viz_df))

        # 3. [í•µì‹¬ ë³€ê²½] ìƒ‰ìƒ êµ¬ë¶„ ë¡œì§
        # íƒ€ê²Ÿ ìœ ì €ì˜ ì¸ë±ìŠ¤ ë° í´ëŸ¬ìŠ¤í„° ID ì°¾ê¸°
        target_idx = self.users_df[self.users_df['student_id'] == target_student_id].index[0]
        target_cluster = self.users_df.iloc[target_idx]['cluster_id']

        # 'color_group' ì»¬ëŸ¼ ìƒì„±: ë‚´ í´ëŸ¬ìŠ¤í„°='Same Group', ë‚˜ë¨¸ì§€='Others'
        viz_df['color_group'] = viz_df['cluster'].apply(
            lambda x: 'ë‚˜ì™€ ê°™ì€ ì„±í–¥ ê·¸ë£¹' if x == target_cluster else 'ë‹¤ë¥¸ ì„±í–¥ ê·¸ë£¹ë“¤'
        )
        plt.figure(figsize=(12, 8))

        # 4. [ìˆ˜ì •ë¨] ë°°ê²½ ì‚°ì ë„ ê·¸ë¦¬ê¸° (12ê°œ ê·¸ë£¹ë³„ ìƒ‰ìƒ ì ìš©)
        sns.scatterplot(
            x='x', y='y',
            hue='cluster',   # 'color_group' ëŒ€ì‹  'cluster' ì»¬ëŸ¼(0~11)ì„ ë°”ë¡œ ì‚¬ìš©
            data=viz_df,
            palette='tab20', # 12ê°œ ì´ìƒ ìƒ‰ìƒì„ ëšœë ·í•˜ê²Œ êµ¬ë¶„í•´ì£¼ëŠ” íŒ”ë ˆíŠ¸ ('tab20', 'Set3' ë“± ì¶”ì²œ)
            alpha=0.6,       # ì ë“¤ì´ ë§ìœ¼ë‹ˆ íˆ¬ëª…ë„ë¥¼ ì•½ê°„ ì£¼ì–´ ê²¹ì¹¨ í™•ì¸
            s=80,
            legend='full'    # ë²”ë¡€ í‘œì‹œ
        )

        # 5. ë‚˜(Me)ì™€ ì¶”ì²œ ë£¸ë©”ì´íŠ¸ í•˜ì´ë¼ì´íŠ¸ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        # (ì´ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´, 12ìƒ‰ ë°°ê²½ ìœ„ì—ì„œë„ ë¹¨ê°„ ë³„ê³¼ íŒŒë€ Xê°€ ì˜ ë³´ì…ë‹ˆë‹¤)
        plt.scatter(viz_df.iloc[target_idx]['x'], viz_df.iloc[target_idx]['y'],
                    c='red', s=400, marker='*', label='ë‚˜ (Me)', edgecolors='white', linewidth=2, zorder=10)

        for i, match in enumerate(top_matches):
            p_idx = self.users_df[self.users_df['student_id'] == match['student_id']].index[0]
            plt.scatter(viz_df.iloc[p_idx]['x'], viz_df.iloc[p_idx]['y'],
                        c='blue', s=200, marker='X', label=f'ì¶”ì²œ {i+1}ìœ„', edgecolors='white', linewidth=1, zorder=10)

            # í™”ì‚´í‘œ ê·¸ë¦¬ê¸° (ê¸°ì¡´ ìœ ì§€)
            plt.arrow(viz_df.iloc[target_idx]['x'], viz_df.iloc[target_idx]['y'],
                      viz_df.iloc[p_idx]['x'] - viz_df.iloc[target_idx]['x'],
                      viz_df.iloc[p_idx]['y'] - viz_df.iloc[target_idx]['y'],
                      color='gray', alpha=0.5, linestyle='--', width=0.002, zorder=9)

        # 6. ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        plt.title(f'AI ê¸°ìˆ™ì‚¬ ë§¤ì¹­ ì „ì²´ ê·¸ë£¹ ë¶„í¬ (í•™ë²ˆ: {target_student_id})', fontsize=16)

        # ë²”ë¡€ ìœ„ì¹˜ ì¡°ì • (ê·¸ë£¹ì´ ë§ì•„ì ¸ì„œ ê·¸ë˜í”„ë¥¼ ê°€ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°–ìœ¼ë¡œ ë¹¼ëŠ” ê²ƒì„ ì¶”ì²œ)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

        plt.grid(True, alpha=0.2)
        plt.tight_layout() # ë²”ë¡€ê°€ ì˜ë¦¬ì§€ ì•Šë„ë¡ ë ˆì´ì•„ì›ƒ ìë™ ì¡°ì •
        plt.show()
    def visualize3d(self, target_student_id, top_matches):
        # 1. t-SNE 3ì°¨ì› ì¶•ì†Œ
        # n_components=3ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ x, y, z ì¢Œí‘œ ìƒì„±
        tsne = TSNE(n_components=3, random_state=42, perplexity=30)
        tsne_points = tsne.fit_transform(self.weighted_features)

        viz_df = pd.DataFrame(tsne_points, columns=['x', 'y', 'z'])
        viz_df['cluster'] = self.users_df['cluster_id']

        # 2. ì‹œê°í™” ì„¤ì •
        fig = plt.figure(figsize=(12, 10))
        ax = fig.add_subplot(111, projection='3d') # 3D ì¶• ìƒì„±

        # 3. 12ê°œ ê·¸ë£¹ë³„ ì‚°ì ë„ ê·¸ë¦¬ê¸°
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì • (tab20)
        cmap = plt.get_cmap('tab20')

        # ê° í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ë£¨í”„ë¥¼ ëŒë©° ì°ì–´ì•¼ ë²”ë¡€(Legend)ê°€ ì˜ˆì˜ê²Œ ë‚˜ì˜µë‹ˆë‹¤.
        unique_clusters = sorted(viz_df['cluster'].unique())
        for cluster in unique_clusters:
            cluster_data = viz_df[viz_df['cluster'] == cluster]
            ax.scatter(cluster_data['x'], cluster_data['y'], cluster_data['z'],
                       label=f'Group {cluster}',
                       c=[cmap(cluster/20)], # tab20 ì»¬ëŸ¬ ë§¤í•‘
                       s=40, alpha=0.4)

        # 4. ë‚˜(Me)ì™€ ì¶”ì²œ ë£¸ë©”ì´íŠ¸ í•˜ì´ë¼ì´íŠ¸
        target_idx = self.users_df[self.users_df['student_id'] == target_student_id].index[0]

        # ë‚˜ (ë¹¨ê°„ ë³„)
        me_x = viz_df.iloc[target_idx]['x']
        me_y = viz_df.iloc[target_idx]['y']
        me_z = viz_df.iloc[target_idx]['z']

        ax.scatter(me_x, me_y, me_z,
                   c='red', s=300, marker='*', label='ë‚˜ (Me)',
                   edgecolors='white', linewidth=1.5, zorder=10)

        # ì¶”ì²œ ë£¸ë©”ì´íŠ¸ (íŒŒë€ X) ë° ì—°ê²°ì„ 
        for i, match in enumerate(top_matches):
            p_idx = self.users_df[self.users_df['student_id'] == match['student_id']].index[0]
            p_x = viz_df.iloc[p_idx]['x']
            p_y = viz_df.iloc[p_idx]['y']
            p_z = viz_df.iloc[p_idx]['z']

            ax.scatter(p_x, p_y, p_z,
                       c='blue', s=150, marker='X', label=f'ì¶”ì²œ {i+1}ìœ„',
                       edgecolors='white', linewidth=1, zorder=10)

            # 3D ì—°ê²°ì„  ê·¸ë¦¬ê¸°
            ax.plot([me_x, p_x], [me_y, p_y], [me_z, p_z],
                    color='gray', alpha=0.5, linestyle='--', linewidth=1)

        # 5. ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        ax.set_title(f'AI ê¸°ìˆ™ì‚¬ ë§¤ì¹­ 3D ë¶„í¬ (í•™ë²ˆ: {target_student_id})', fontsize=16)
        ax.set_xlabel('t-SNE X')
        ax.set_ylabel('t-SNE Y')
        ax.set_zlabel('t-SNE Z')

        # ì´ˆê¸° ë·° ê°ë„ ì„¤ì • (elev=ìœ„ì•„ë˜ ê°ë„, azim=ì¢Œìš° íšŒì „ ê°ë„)
        # ì´ ê°ë„ë¥¼ ì¡°ì ˆí•´ì„œ ê°€ì¥ ì˜ ë³´ì´ëŠ” ë·°ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
        ax.view_init(elev=30, azim=45)

        # ë²”ë¡€ë¥¼ ê·¸ë˜í”„ ë°–ìœ¼ë¡œ
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.tight_layout()
        plt.show()

# ---------------------------------------------------------
# 2. ì‹¤í–‰ë¶€
# ---------------------------------------------------------
# 1. ì—”ì§„ ì´ˆê¸°í™” (íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# ì˜ˆ: 'dormitory_users.json' ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
file_path = 'dormitory_users.json'
engine = DormMatchAI_Advanced(file_path)
engine.load_and_preprocess()
engine.train_clustering()

# 2. í…ŒìŠ¤íŠ¸í•  ëœë¤ ìœ ì € ì„ ì •
import random
random_idx = random.randint(0, len(engine.users_df) - 1)
test_student_id = engine.users_df.iloc[random_idx]['student_id']

# 3. ë§¤ì¹­ ì‹¤í–‰
matches, my_id = engine.find_best_match(test_student_id)

# 4. ê²°ê³¼ ì¶œë ¥
print(f"\nğŸ“¢ [ë§¤ì¹­ ê²°ê³¼ ë¦¬í¬íŠ¸] ì‹ ì²­ì í•™ë²ˆ: {my_id}")
print("="*65)
for i, m in enumerate(matches):
    # [ìˆ˜ì • 5] í‚¤ ì´ë¦„ ë³€ê²½ (me_smoke -> is_smoker)
    smoke_txt = "í¡ì—°" if m['is_smoker'] else "ë¹„í¡ì—°"
    drink_txt = "ìŒì£¼" if m['is_drinker'] else "ë¹„ìŒì£¼"

    print(f"ğŸ¥‡ ì¶”ì²œ {i+1}ìœ„ (í•™ë²ˆ: {m['student_id']}) - ì¼ì¹˜ìœ¨: {m['match_score']:.1f}%")
    print(f"   í•™ê³¼: {m['major']} ({m['age']}ì„¸) | {smoke_txt} / {drink_txt}")

    expl = m['explanation']
    print(f"   ğŸ‘ [ì¼ì¹˜ í•­ëª©]: {len(expl['match'])}ê°œ (ìˆ˜ë©´, ì²­ê²° ë“± ì£¼ìš” ì„±í–¥ ì¼ì¹˜)")

    if expl['conflict']:
        # ë„ˆë¬´ ë§ìœ¼ë©´ 3ê°œë§Œ ì¶œë ¥
        conflicts = expl['conflict'][:3]
        print(f"   âš ï¸ [ì¡°ìœ¨ í•„ìš”]: {', '.join(conflicts)} ... ì™¸ {len(expl['conflict'])-3}ê±´")
    else:
        print(f"   âœ¨ [Perfect]: ê°ˆë“± ìš”ì†Œê°€ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")
    print("-" * 65)

# 5. ì‹œê°í™”
engine.visualize1(test_student_id, matches)
engine.visualize2(test_student_id, matches)

engine.visualize3d(test_student_id, matches)

def analyze_cluster_personas_advanced(engine):
    # 1. ë¶„ì„í•  ì»¬ëŸ¼ (ì—”ì§„ì— ì„¤ì •ëœ ê°€ì¤‘ì¹˜ í‚¤ê°’ë“¤ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°)
    # ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¥¼ ì ëŠ” ê²ƒë³´ë‹¤, ì—”ì§„ì´ ì‚¬ìš©í•œ ì»¬ëŸ¼ì„ ê·¸ëŒ€ë¡œ ì“°ëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.
    valid_cols = engine.feature_cols

    # í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ê³„ì‚° (ì‚¬ëŒì´ ë³´ê¸°ì—” ì›ë³¸ ë°ì´í„° í‰ê· ì´ ì´í•´í•˜ê¸° ì¢‹ìœ¼ë¯€ë¡œ users_df ì‚¬ìš© ìœ ì§€)
    cluster_means = engine.users_df.groupby('cluster_id')[valid_cols].mean()

    print("\nğŸ“Š [AI ê¸°ìˆ™ì‚¬ ìœ í˜• ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸]")
    print("=" * 70)

    for cluster_id in cluster_means.index:
        row = cluster_means.loc[cluster_id]

        # --- 1. ëª…ì‚¬ ê²°ì • (ìˆ˜ë©´ íŒ¨í„´) ---
        noun = "ì¼ë°˜ëŸ¬"
        if row['sleep_habit'] > 0.6: noun = "ì˜¬ë¹¼ë¯¸"
        elif row['sleep_habit'] < 0.4: noun = "ì–¼ë¦¬ë²„ë“œ"

        # --- 2. í˜•ìš©ì‚¬ ê²°ì • (ë¦¬ìŠ¤íŠ¸ì— ë‹´ê¸°) ---
        adjectives = []

        # ì²­ì†Œ (ê°’ì´ ë‚®ì„ìˆ˜ë¡ ìì£¼ í•¨)
        if row['clean_cycle'] < 1.0: adjectives.append("ê²°ë²½ì¦")
        elif row['clean_cycle'] < 1.8: adjectives.append("ê¹”ë”í•œ")
        elif row['clean_cycle'] > 2.2: adjectives.append("í„¸í„¸í•œ")

        # ì†ŒìŒ
        if row['phone_noise'] > 0.6: adjectives.append("ì˜ˆë¯¼ë³´ìŠ¤")
        elif row['phone_noise'] < 0.4: adjectives.append("ë¬´ë˜í•œ")

        # [ìˆ˜ì •] ë¦¬ìŠ¤íŠ¸ë¥¼ ì˜ˆìœ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜ˆ: ['ê¹”ë”', 'ì¡°ìš©'] -> "ê¹”ë” ì¡°ìš©")
        adj_str = " ".join(adjectives)
        final_name = f"{adj_str} {noun} ìœ í˜•" if adj_str else f"{noun} ìœ í˜•"

        # ë¹„ìœ¨ ê³„ì‚°
        ratio = len(engine.users_df[engine.users_df['cluster_id'] == cluster_id]) / len(engine.users_df) * 100

        print(f"ğŸ·ï¸  [Cluster {cluster_id}]: \"{final_name}\" (ë¹„ìœ¨: {ratio:.1f}%)")
        print("-" * 40)

        # ì£¼ìš” ìˆ˜ì¹˜ ì¶œë ¥
        for col in valid_cols:
            val = row[col]
            # ìˆ˜ì¹˜ê°€ 0/1 ë²”ì£¼í˜•ì´ë©´ í•´ì„ì„ ë•ê¸° ìœ„í•´ ì¶œë ¥
            print(f"    â€¢ {col:<20} : {val:.2f}")

        print("=" * 70)

# ì‹¤í–‰
analyze_cluster_personas_advanced(engine)


from sklearn.ensemble import RandomForestClassifier
import pandas as pd

def analyze_feature_impact(engine):
    # 1. X ë°ì´í„° ì„¤ì • [ì¤‘ìš” ìˆ˜ì •]
    # K-Meansê°€ ì‹¤ì œë¡œ 'ë¬´ì—‡'ì„ ë³´ê³  ë‚˜ëˆ´ëŠ”ì§€ ì•Œê¸° ìœ„í•´ 'ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë°ì´í„°'ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    X = engine.weighted_features
    y = engine.users_df['cluster_id']

    # 2. ëœë¤ í¬ë ˆìŠ¤íŠ¸ë¡œ ì—­ì¶”ì 
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X, y)

    # 3. ì¤‘ìš”ë„ ì¶”ì¶œ
    importances = pd.Series(clf.feature_importances_, index=X.columns)
    importances = importances.sort_values(ascending=False)

    # 4. ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Š [í´ëŸ¬ìŠ¤í„°ë§ ì˜í–¥ë ¥ ë¶„ì„] AIê°€ ë¬´ì—‡ì„ ë³´ê³  ë‚˜ëˆ´ëŠ”ê°€? (ê°€ì¤‘ì¹˜ í¬í•¨)")
    print("=" * 60)
    for feature, score in importances.items():
        if score > 0.30:
            status = "âœ… ê²°ì •ì  (ë²”ì¸)"
        elif score > 0.15:
            status = "âš ï¸ ì˜í–¥ ìˆìŒ"
        elif score > 0.05:
            status = "ğŸ” ë¯¸ë¯¸í•¨"
        else:
            status = "âŒ ë¬´ì‹œë¨"

        print(f" â€¢ {feature:<20} : {score:.4f}  [{status}]")
    print("=" * 60)

# ì‹¤í–‰
analyze_feature_impact(engine)

from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

def find_optimal_k(engine, max_k=20):
    inertias = []
    silhouettes = []
    K_range = range(2, max_k + 1) # 2ê°œë¶€í„° 20ê°œê¹Œì§€ í…ŒìŠ¤íŠ¸

    print(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K)ë¥¼ 2ë¶€í„° {max_k}ê¹Œì§€ í…ŒìŠ¤íŠ¸ ì¤‘...", end="")

    for k in K_range:
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        kmeans = KMeans(n_clusters=k, random_state=42)
        kmeans.fit(engine.weighted_features)

        # 1. ê´€ì„±(Inertia): ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (êµ°ì§‘ ë‚´ ì‘ì§‘ë„)
        inertias.append(kmeans.inertia_)

        # 2. ì‹¤ë£¨ì—£ ì ìˆ˜(Silhouette): 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (êµ°ì§‘ ê°„ ë¶„ë¦¬ë„)
        score = silhouette_score(engine.weighted_features, kmeans.labels_)
        silhouettes.append(score)
        print(".", end="") # ì§„í–‰ìƒí™© í‘œì‹œ

    print(" ì™„ë£Œ!")

    # --- ì‹œê°í™” ---
    fig, ax1 = plt.subplots(figsize=(14, 6))

    # ì™¼ìª½ ì¶•: ì—˜ë³´ìš° ê¸°ë²• (Inertia)
    color = 'tab:blue'
    ax1.set_xlabel('í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K)', fontsize=12)
    ax1.set_ylabel('Inertia (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)', color=color, fontsize=12)
    ax1.plot(K_range, inertias, 'o--', color=color, label='Inertia')
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.set_xticks(K_range)
    ax1.grid(True, alpha=0.3)

    # ì˜¤ë¥¸ìª½ ì¶•: ì‹¤ë£¨ì—£ ì ìˆ˜
    ax2 = ax1.twinx()
    color = 'tab:red'
    ax2.set_ylabel('ì‹¤ë£¨ì—£ ì ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)', color=color, fontsize=12)
    ax2.plot(K_range, silhouettes, 's-', color=color, label='Silhouette')
    ax2.tick_params(axis='y', labelcolor=color)

    # ì œëª© ë° ê·¸ë˜í”„ í‘œì‹œ
    plt.title('ì ì • í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K) ì°¾ê¸°: ì—˜ë³´ìš° & ì‹¤ë£¨ì—£ ë¶„ì„', fontsize=16)
    fig.tight_layout()
    plt.show()

# ì‹¤í–‰
find_optimal_k(engine, max_k=20)