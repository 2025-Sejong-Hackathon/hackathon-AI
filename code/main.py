from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from datetime import datetime
import requests
from .simulate import predict_day, get_model
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import json
from typing import List, Dict, Any
import os

# ======================
# ë§¤ì¹­ ëª¨ë¸ ì„¤ì •
# ======================
W_P = 4  # Personality (ì„±ê²©/ì˜ˆë¯¼)
W_S = 3  # Sleep (ìˆ˜ë©´)
W_C = 2  # Cleanliness (ì²­ê²°)

weight_A = {
    "sleep_habit": W_S, "wake_up": W_S, "activity_time": W_S, "out_return": W_S,
    "clean_immediate": W_C, "desk_status": W_C, "clean_cycle": W_C, "other_seat_tol": W_C,
    "phone_noise": W_P, "light_sensitivity": W_P, "key_mouse_noise": W_P, "alarm_habit": W_P,
    "social_willingness": W_P, "friend_invite": W_P, "dorm_stay": W_P, "space_privacy": W_P
}

class DormMatchAI_Server:
    def __init__(self, data_path):
        self.data_path = data_path
        self.users_df = None
        self.weighted_features_df = None
        self.weights = weight_A
        self.scaler = MinMaxScaler()
        self.kmeans = KMeans(n_clusters=12, random_state=42)
        
        self.text_map = {
            "sleep_habit": {0: "12ì‹œì „ ì·¨ì¹¨", 1: "ìƒˆë²½ ì·¨ì¹¨"},
            "wake_up": {0: "ëŠ¦ì /ì˜¤í›„ ê¸°ìƒ", 1: "ì•„ì¹¨ ê¸°ìƒ"},
            "activity_time": {0: "ë‚® í™œë™(ì•„ì¹¨í˜•)", 1: "ë°¤ í™œë™(ì˜¬ë¹¼ë¯¸)"},
            "out_return": {0: "ìƒê´€ì—†ìŒ", 1: "ì—°ë½/ì•Œë¦¼ í•„ìš”"},
            "dorm_stay": {0: "ì£¼ë¡œ ë°–ì—ì„œ ë³´ëƒ„", 1: "ì£¼ë¡œ ê¸°ìˆ™ì‚¬ì— ìˆìŒ"},
            "clean_cycle": {0: "ë§¤ì¼ ì²­ì†Œ", 1: "3ì¼ë§ˆë‹¤", 2: "1ì£¼ë§ˆë‹¤", 3: "1ë‹¬ë§ˆë‹¤"},
            "clean_immediate": {0: "ë‚˜ì¤‘ì— ì¹˜ì›€", 1: "ë°”ë¡œë°”ë¡œ ì¹˜ì›€"},
            "desk_status": {0: "ì–´ìˆ˜ì„ í•¨(ì¸ê°„ë¯¸)", 1: "ê¹”ë”í•˜ê²Œ ì •ë¦¬"},
            "other_seat_tol": {0: "ìƒê´€ì—†ìŒ", 1: "ë‚´ ìë¦¬ ê±´ë“¤ì§€ë§ˆ"},
            "phone_noise": {0: "ì•ˆì—ì„œ í†µí™” OK", 1: "ë°–ì—ì„œ í†µí™”"},
            "light_sensitivity": {0: "ë¶ˆ ì¼œë„ ì˜ ì ", 1: "ë¶ˆ êº¼ì•¼ ì "},
            "key_mouse_noise": {0: "ìƒê´€ì—†ìŒ", 1: "ë¬´ì†ŒìŒ ì„ í˜¸"},
            "alarm_habit": {0: "ì˜ ëª» ë“£ëŠ” í¸", 1: "ë°”ë¡œ ë„ê³  ì¼ì–´ë‚¨"},
            "space_privacy": {0: "ë¬¼ê±´ ê³µìœ  ê°€ëŠ¥", 1: "ì² ì €í•˜ê²Œ ë¶„ë¦¬"},
            "social_willingness": {0: "ê°œì¸ì£¼ì˜(í˜¼ì)", 1: "ì¹œëª© ë„ëª¨(í•¨ê»˜)"},
            "friend_invite": {0: "ì¹œêµ¬ ì´ˆëŒ€ ìì œ", 1: "ì¹œêµ¬ ì´ˆëŒ€ í™˜ì˜"},
            "is_smoker": {True: "í¡ì—°ì", False: "ë¹„í¡ì—°ì"},
            "wants_smoker": {True: "í¡ì—° ë£¸ë©” OK", False: "ë¹„í¡ì—° ë£¸ë©” ì„ í˜¸"},
            "is_drinker": {True: "ìŒì£¼ ì¦ê¹€", False: "ë¹„ìŒì£¼"},
            "wants_drinker": {True: "ìŒì£¼ ë£¸ë©” OK", False: "ë¹„ìŒì£¼ ë£¸ë©” ì„ í˜¸"},
            "sensitive_heat": {True: "ë”ìœ„ ë§ì´ íƒ", False: "ë”ìœ„ ì˜ ì°¸ìŒ"},
            "sensitive_cold": {True: "ì¶”ìœ„ ë§ì´ íƒ", False: "ì¶”ìœ„ ì˜ ì°¸ìŒ"}
        }
        
        self.col_name_map = {
            "sleep_habit": "ì·¨ì¹¨ì‹œê°„", "wake_up": "ê¸°ìƒì‹œê°„", "activity_time": "ì£¼í™œë™ì‹œê°„",
            "dorm_stay": "ê¸°ìˆ™ì‚¬ ì²´ë¥˜", "out_return": "ì™¸ì¶œ/ë³µê·€ ì—°ë½",
            "clean_cycle": "ì²­ì†Œì£¼ê¸°", "clean_immediate": "ì •ë¦¬ìŠµê´€", 
            "desk_status": "ì±…ìƒìƒíƒœ", "other_seat_tol": "íƒ€ì¸ì˜ì—­ í—ˆìš©",
            "phone_noise": "í†µí™”ì†ŒìŒ", "light_sensitivity": "ìˆ˜ë©´ ë“±(Light)", 
            "key_mouse_noise": "íƒ€ê±´/ë§ˆìš°ìŠ¤ ì†ŒìŒ", "alarm_habit": "ì•ŒëŒ ìŠµê´€",
            "space_privacy": "ê³µìš©ë¬¼í’ˆ/ê³µê°„",
            "social_willingness": "ì‚¬íšŒì„±", "friend_invite": "ì¹œêµ¬ ì´ˆëŒ€",
            "is_smoker": "í¡ì—°ì—¬ë¶€", "wants_smoker": "í¡ì—°ë£¸ë©” í—ˆìš©",
            "is_drinker": "ìŒì£¼ì—¬ë¶€", "wants_drinker": "ìŒì£¼ë£¸ë©” í—ˆìš©",
            "sensitive_heat": "ë”ìœ„ ë¯¼ê°ë„", "sensitive_cold": "ì¶”ìœ„ ë¯¼ê°ë„"
        }
        
        self.feature_cols = list(self.weights.keys())
    
    def load_and_train(self):
        print("â³ ë°ì´í„° ë¡œë”© ë° ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        with open(self.data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        required_fields = ['student_id', 'gender'] + self.feature_cols
        valid_data = [record for record in data if all(field in record for field in required_fields)]
        
        print(f"âœ… ì „ì²´ {len(data)}ê°œ ì¤‘ ìœ íš¨í•œ ë°ì´í„° {len(valid_data)}ê°œ ë¡œë“œ")
        
        if len(valid_data) == 0:
            raise ValueError("ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        self.users_df = pd.DataFrame(valid_data)
        features_norm = self.scaler.fit_transform(self.users_df[self.feature_cols])
        
        weighted_data = features_norm.copy()
        for i, col in enumerate(self.feature_cols):
            weighted_data[:, i] *= self.weights[col]
        
        self.weighted_features_df = pd.DataFrame(weighted_data, columns=self.feature_cols, index=self.users_df.index)
        self.users_df['cluster_id'] = self.kmeans.fit_predict(self.weighted_features_df)
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    
    def preprocess_input(self, user_data: dict):
        input_df = pd.DataFrame([user_data])
        norm_data = self.scaler.transform(input_df[self.feature_cols])
        
        weighted_input = norm_data.copy()
        for i, col in enumerate(self.feature_cols):
            weighted_input[:, i] *= self.weights[col]
        
        return pd.DataFrame(weighted_input, columns=self.feature_cols)
    
    def explain_match_detail(self, user_data: dict, partner_row: pd.Series):
        match_items = []
        mismatch_items = []
        
        for col in self.feature_cols:
            val_me = user_data[col]
            val_partner = partner_row[col]
            col_name_kr = self.col_name_map.get(col, col)
            
            if val_me == val_partner:
                match_items.append(col_name_kr)
            else:
                my_val_txt = self.text_map.get(col, {}).get(val_me, str(val_me))
                pt_val_txt = self.text_map.get(col, {}).get(val_partner, str(val_partner))
                mismatch_items.append({
                    "category": col_name_kr,
                    "my_value": my_val_txt,
                    "mate_value": pt_val_txt
                })
        
        return match_items, mismatch_items
    
    def recommend(self, user_data: dict, count=5, page=1):
        target_student_id = user_data['student_id']
        target_gender = user_data['gender']
        
        target_vec = self.preprocess_input(user_data)
        target_cluster = self.kmeans.predict(target_vec)[0]
        
        candidates = self.users_df[
            (self.users_df['student_id'] != target_student_id) &
            (self.users_df['gender'] == target_gender) &
            (self.users_df['cluster_id'] == target_cluster)
        ].copy()
        
        if len(candidates) < count*page:
            candidates = self.users_df[
                (self.users_df['student_id'] != target_student_id) &
                (self.users_df['gender'] == target_gender)
            ].copy()
        
        if len(candidates) == 0:
            return []
        
        candidate_vecs = self.weighted_features_df.loc[candidates.index]
        sims = cosine_similarity(target_vec, candidate_vecs)[0]
        
        candidates['match_score'] = sims * 100
        sorted_candidates = candidates.sort_values(by='match_score', ascending=False)
        
        start_idx = (page - 1) * count
        end_idx = start_idx + count
        top_matches = sorted_candidates.iloc[start_idx:end_idx]
        
        results = []
        for _, row in top_matches.iterrows():
            m_items, mm_items = self.explain_match_detail(user_data, row)
            results.append({
                "student_id": row['student_id'],
                "major": row['major'],
                "match_rate": round(row['match_score'], 1),
                "is_smoker": bool(row['is_smoker']),
                "is_drinker": bool(row['is_drinker']),
                "sensitive_heat": bool(row.get('sensitive_heat', False)),
                "sensitive_cold": bool(row.get('sensitive_cold', False)),
                "match_items": m_items,
                "mismatch_items": mm_items
            })
        
        return results

# Pydantic ëª¨ë¸
class StudentInput(BaseModel):
    student_id: str
    age: int
    gender: str
    major: str
    is_smoker: bool
    wants_smoker: bool
    is_drinker: bool
    wants_drinker: bool
    sensitive_heat: bool
    sensitive_cold: bool
    sleep_habit: int
    wake_up: int
    activity_time: int
    clean_immediate: int
    desk_status: int
    clean_cycle: int
    out_return: int
    other_seat_tol: int
    phone_noise: int
    light_sensitivity: int
    key_mouse_noise: int
    space_privacy: int
    alarm_habit: int
    social_willingness: int
    friend_invite: int
    dorm_stay: int

app = FastAPI(
    title="Dormitory AI Service",
    description="ì„¸íƒì‹¤ í˜¼ì¡ë„ ì˜ˆì¸¡ + ë¹¨ë˜ì§€ìˆ˜ + ë£¸ë©”ì´íŠ¸ ë§¤ì¹­ AI API",
    version="2.0"
)

# ì „ì—­ ë§¤ì¹­ ì—”ì§„ ë° ì„¸íƒ ëª¨ë¸
matching_engine = None
laundry_model = None

@app.on_event("startup")
def startup_event():
    global matching_engine, laundry_model
    print("ğŸš€ ì„œë²„ ì‹œì‘ ì¤‘...")
    
    # ë§¤ì¹­ ëª¨ë¸ ë¡œë“œ
    dummy_file_path = "data/dormitory_users.json"
    matching_engine = DormMatchAI_Server(dummy_file_path)
    matching_engine.load_and_train()
    
    # ì„¸íƒ ëª¨ë¸ ë¡œë“œ (lazy loading)
    laundry_model = get_model()
    
    print("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# ======================
# í—¬ìŠ¤ ì²´í¬
# ======================
@app.get("/health")
def health_check():
    if matching_engine is None:
        raise HTTPException(status_code=503, detail="Service Unavailable - Model not loaded")
    return {"status": "healthy", "service": "dormitory-ai-service"}

# ======================
# ë£¸ë©”ì´íŠ¸ ë§¤ì¹­ API
# ======================
@app.post("/recommend")
def get_recommendation(user_input: StudentInput, count: int = 5, page: int = 1):
    if matching_engine is None:
        raise HTTPException(status_code=500, detail="Model is not loaded")
    
    try:
        user_dict = user_input.dict()
        
        gender_map = {
            "MALE": "ë‚¨ì„±",
            "FEMALE": "ì—¬ì„±",
            "male": "ë‚¨ì„±",
            "female": "ì—¬ì„±"
        }
        
        if user_dict["gender"] in gender_map:
            user_dict["gender"] = gender_map[user_dict["gender"]]
        
        recommendations = matching_engine.recommend(user_dict, count=count, page=page)
        return recommendations
    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ======================
# 1ï¸âƒ£ í˜¼ì¡ë„ ì˜ˆì¸¡ API
# ======================
@app.get("/predict")
def predict(date: str):
    if laundry_model is None:
        raise HTTPException(status_code=500, detail="Laundry model is not loaded")
    
    target_date = datetime.strptime(date, "%Y-%m-%d").date()
    result = predict_day(laundry_model, target_date)
    peak_hour = int(
        result.loc[result["predicted_congestion"].idxmax(), "hour"]
    )
    recommend_hour = int(
        result.loc[result["predicted_congestion"].idxmin(), "hour"]
    )
    return {
        "date": date,
        "peak_message": f"ğŸ”¥ {peak_hour}ì‹œëŠ” ë§¤ìš° í˜¼ì¡í•  ì˜ˆì •ì´ì—ìš”",
        "recommend_message": f"ğŸ‘ {recommend_hour}ì‹œ ì´í›„ ì´ìš©ì„ ì¶”ì²œí•´ìš”",
        "timeline": result[
            ["hour", "predicted_congestion"]
        ].to_dict(orient="records")
    }

# ======================
# 2ï¸âƒ£ ì˜¤ëŠ˜ì˜ ë¹¨ë˜ì§€ìˆ˜ API
# ======================
SERVICE_KEY = "5ZtcPG9SqpW07BI98G3LUy3ajs6wkbPtFUU5icGD3JhEFtBxXK2eCfnibYLdFi9oZYXCLAv2K7cBmOjzFjQWjg=="
NX, NY = 61, 126
BASE_TIMES = [200, 500, 800, 1100, 1400, 1700, 2000, 2300]

def laundry_comment(index):
    if index >= 70:
        return "ì˜¤ëŠ˜ ë¹¨ë˜í•˜ê¸° ì¢‹ì•„ìš” â˜€ï¸"
    elif index >= 40:
        return "ì˜¤ëŠ˜ ë¹¨ë˜í•˜ê¸° ë³´í†µì´ì—ìš” ğŸŒ¥ï¸"
    else:
        return "ì˜¤ëŠ˜ ë¹¨ë˜í•˜ê¸° ì•ˆ ì¢‹ì•„ìš” â˜”ï¸"

def laundry_index(temp, humidity, rain):
    score = 100
    score -= humidity * 0.4
    score -= rain * 20
    score += (temp - 20) * 1.5
    return max(0, min(100, score))

@app.get("/laundry/today")
def get_laundry_message():
    now = datetime.now()
    today = now.strftime("%Y%m%d")
    current_time = int(now.strftime("%H%M"))
    base_time = None
    for t in reversed(BASE_TIMES):
        if current_time >= t:
            base_time = f"{t:04d}"
            break
    if base_time is None:
        base_time = "2300"
    url = "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
    params = {
        "serviceKey": SERVICE_KEY,
        "numOfRows": 1000,
        "pageNo": 1,
        "dataType": "JSON",
        "base_date": today,
        "base_time": base_time,
        "nx": NX,
        "ny": NY
    }
    res = requests.get(url, params=params).json()
    items = res["response"]["body"]["items"]["item"]
    weather = {}
    for item in items:
        if item["fcstDate"] == today:
            cat = item["category"]
            if cat in ["TMP", "REH", "PCP"] and cat not in weather:
                weather[cat] = item["fcstValue"]
    temp = float(weather.get("TMP", 20))
    humidity = float(weather.get("REH", 50))
    
    # ê°•ìˆ˜ëŸ‰ íŒŒì‹± (1.0mm, 2mm ë“±ì˜ í˜•ì‹ ì²˜ë¦¬)
    pcp_value = weather.get("PCP", "ê°•ìˆ˜ì—†ìŒ")
    if pcp_value == "ê°•ìˆ˜ì—†ìŒ":
        rain = 0
    else:
        # "mm" ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ
        rain = float(pcp_value.replace("mm", "").strip())
    
    index = laundry_index(temp, humidity, rain)
    return {
        "laundry_message": laundry_comment(index)
    }

@app.get("/notices")
def get_dorm_notices():
    if not os.path.exists("data/dorm_notices.json"):
        raise HTTPException(status_code=404, detail="ê³µì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with open("data/dorm_notices.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    return {
        "count": len(data),
        "notices": data
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)